{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<H1><center>Neural Architecture Search using MCGRAN</center></H1>"
      ],
      "metadata": {
        "id": "9JrMWRR58WDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-conditional GRAN"
      ],
      "metadata": {
        "id": "R8Brb9S19Nfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We model the conditional graph generation as an affine transformation based on given contraints.\n",
        "We use $ \\textrm{MLP}_{scale} $ and $ \\textrm{MLP}_{shift} $ to geometrically transform the feature space of bernoulli mixture components.\n",
        "Our intention with this transformation is to separate the various constraints(classes or categories) of graphs into distinct real space.\n",
        "\n",
        "\\begin{align}\n",
        "\t\\alpha_{1},..., \\alpha_{K} = \\textrm{Softmax}(\\sum_{i \\in \\boldsymbol{b}_{t},1 \\leq j \\leq i} \\textrm{MLP}_{\\alpha} (h_{i}^{R} - h_{j}^{R}) \\otimes \\textrm{MLP}_{scale}(c_{i}) + \\textrm{MLP}_{shift}(c_{i}))\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\t\\theta_{1,i,j},..., \\theta_{K,i,j} = \\textrm{Sigmoid}(\\textrm{MLP}_{\\theta} (h_{i}^{R} - h_{j}^{R})  \\otimes \\textrm{MLP}_{scale}(c_{i}) + \\textrm{MLP}_{shift}(c_{i}))\n",
        "\\end{align}\n",
        "\n",
        "In equations, $ M $ denote the number of constraints enforced on each node $ i $, $ c_{i} \\in \\mathbb{R}^{M} $ represents the constraints vector associated with each node $ i $, $ \\textrm{MLP}_{scale} \\in  \\mathbb{R}^{K \\times H}$ is a RELU-based hidden layer capturing features for scaling factor, and $ \\textrm{MLP}_{shift} \\in  \\mathbb{R}^{K \\times H} $ is a RELU-based hidden layer capturing features for shift factor. $ K $ denote the number of mixture components and $ H $ denote the hidden dimension size."
      ],
      "metadata": {
        "id": "UtAUMszI-KMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph-based Auto-regressive Affine Transformations"
      ],
      "metadata": {
        "id": "AlTfISfM_yn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the structure of the graph, that is, the adjacency matrix $ A $ for each graph $G = (V,E)$. We create node level features using 1D convolutions. We use a block of three 1D convolutional hidden layers stacked together to capture features for each vertices $ v $, where $ \\textrm{CNN}(A): \\mathbb{R}^{|V| \\times |V|} \\rightarrow \\mathbb{R}^{|V| \\times H}$, where adjacency matrix denoted as $ A \\in \\mathbb{R}^{|V| \\times |V|} $. Each channel of convolution captures the information specific to a node.\n",
        "\n",
        "Then, we apply auto-regressive affine transformation to create node labels.  In graph-based auto-regressive affine transformations, for each node label prediction, we use three information.  First information comes from the node features which we captured using the CNN. Let us denote node features for a node $v\\in V$ as $q_v\\in\\mathbb{R}^{H}$ with $H$ being the feature dimension.\n",
        "\n",
        "Second information comes from the nodes features of the other connected nodes. This acts as neighbor constraints to predict the current node label. For a node $v\\in V$ of a graph $G = (V,E)$ its set of neighboring features is given as\n",
        "\\[\n",
        "Neigh(v) = \\{ q_s ~|~ (s,v) \\in E \\}\n",
        "\\]\n",
        "We could also define $NAgg(v): \\mathbb{R}^{|Neigh(v)| \\times H} \\rightarrow \\mathbb{R}^{H}$\n",
        "\n",
        "\\begin{align}\n",
        "\tNAgg(v) = \\sum\\limits_{q\\in\\{ q_s ~|~ (s,v) \\in E \\}}\n",
        "\\end{align}\n",
        "\n",
        "For each node $ v $, we apply affine transformation based on node neighbors with one scaling factor $ \\textrm{MLP}_{scale}(NAgg(v)) $ and one shift factor $ \\textrm{MLP}_{shift}(NAgg(v)) $. \n",
        "\n",
        "Third information comes from the graph level constraint. We apply geometric transformation based on graph constraints with one scaling factor  $ \\textrm{MLP}_{scale}(c_{v}) $ and one shift factor $ \\textrm{MLP}_{shift}(c_{v}) $.\n",
        "\n",
        "The $ c_{v} \\in \\mathbb{R}^{M} $ represents the constraints vector associated with each node $ v $, the $ M $ denote the number of constraints enforced on each node $ v $, the $ \\textrm{MLP}_{scale} \\in  \\mathbb{R}^{H}$ is a RELU-based hidden layer capturing features for scaling factor, and the $ \\textrm{MLP}_{shift} \\in  \\mathbb{R}^{ H} $ is a RELU-based hidden layer capturing features for shift factor. The $ H $ denote the hidden dimension size.\n",
        "\n",
        "%From a social network perspective, each person (node) uses the information he or she knows, then collects information from his or her friends, and finally collects information other sources (books or internet) to make a decision.\n",
        "%The same process is applied here.\n",
        "\n",
        "We can combine all three information to predict for each node $ v $ the label as shown in equation~\\ref{eq:mcgran_node_label_equation}.\n",
        "\n",
        "\\begin{align}\n",
        "\tv = \\textrm{Softmax}(\\textrm{CNN}(v) \\otimes \\textrm{MLP}_{scale}(NAgg(v)) \\otimes \\textrm{MLP}_{scale}(c_{v})   + \\textrm{MLP}_{shift}(NAgg(v)) + \\textrm{MLP}_{shift}(c_{v}))\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "fh8FJykCAA1C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhRxOd1qivxo",
        "outputId": "0efe8722-76a3-4101-e727-ceebb081109d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "HPIwYuQBBGf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20a3c30-fa92-49de-f811-9be8616beb64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[K     |████████████████▎               | 834.1 MB 1.2 MB/s eta 0:11:18tcmalloc: large alloc 1147494400 bytes == 0x39b32000 @  0x7fb54d1fe615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████▋           | 1055.7 MB 1.2 MB/s eta 0:07:57tcmalloc: large alloc 1434370048 bytes == 0x7e188000 @  0x7fb54d1fe615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |██████████████████████████▏     | 1336.2 MB 1.2 MB/s eta 0:04:15tcmalloc: large alloc 1792966656 bytes == 0x2fba000 @  0x7fb54d1fe615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 1637.0 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1636999168 bytes == 0x6dda2000 @  0x7fb54d1fd1e7 0x4d3280 0x4d330c 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ced5 0x4fdff5 0x49ced5 0x55e571\n",
            "tcmalloc: large alloc 2046255104 bytes == 0xcf6cc000 @  0x7fb54d1fe615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ced5 0x4fdff5 0x49ced5 0x55e571 0x5d7cf1 0x4fea58\n",
            "\u001b[K     |████████████████████████████████| 1637.0 MB 10 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11.0+cu113) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.9.24)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dn1buYZHWGw",
        "outputId": "cd8e1a36-67f9-4d21-e396-a7d30a114232"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w9MZa_zMF4o3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0802b31-1479-4dca-f1f7-4b2962729816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0   152M      0  0:00:03  0:00:03 --:--:--  152M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6b80AUMxHaLc"
      },
      "outputs": [],
      "source": [
        "#!g++ -O2 -std=c++11 -o drive/MyDrive/Research-NAS/MCGRAN/utils/orca/orca.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "80BIYLdU27qm"
      },
      "outputs": [],
      "source": [
        "#!chmod +x drive/MyDrive/Research-NAS/MCGRAN/utils/orca/orca"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4RW8Zz8COrZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration Settings"
      ],
      "metadata": {
        "id": "_TZqIwxeCR0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the configurable settings for working the GRAN model are specified in the yaml files located in the config folder.  There are five sections of parameters in the configuration files:\n",
        "\n",
        "1.   General experimental parameters\n",
        "2.   Dataset parameters\n",
        "3.   Model parameters\n",
        "4.   Training parameters\n",
        "5.   Test parameters"
      ],
      "metadata": {
        "id": "njK-vrjtCbbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General experimental parameters"
      ],
      "metadata": {
        "id": "iNQDSbHvEOVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name of the experiment\n",
        "> **exp_name**: *MCGRAN*\n",
        "\n",
        "The experiment directory folder name if not already present.  This folder will contain the training and evaluation metrics.\n",
        "\n",
        "> **exp_dir**: *exp/MCGRAN/* \n",
        "\n",
        "Name of the runner class name from gran_runner_*.py file\n",
        "> **runner**: *GranRunner_Evaluation*\n",
        "\n",
        "Distributed training of the model in multiple machines. Always set to false.  We did not test with true.\n",
        "> **use_horovod**: *false*\n",
        "\n",
        "GRU related settings. Always set to true. we did not test with false.\n",
        "> **use_gpu**: *true*      \n",
        "\n",
        "Cuda device id\n",
        "> **device**: *cuda:0*  \n",
        "\n",
        "Number of GPUs\n",
        "> **gpus**: [0]\n",
        "\n",
        "Random seed for reproducing the experiments\n",
        "> seed: 78123456"
      ],
      "metadata": {
        "id": "ygg4c_c3ESS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python drive/MyDrive/Research-NAS/MCGRAN/run_exp.py -c drive/MyDrive/Research-NAS/MCGRAN/config/mcgran.yaml -t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slxomCDMHHYw",
        "outputId": "062da337-6a95-4e38-ac7f-c30c92cd2b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from file... This may take a few minutes...\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Research-NAS/MCGRAN/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Research-NAS/MCGRAN/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Loaded dataset in 44 seconds\n",
            "INFO  | 2022-12-08 12:21:14,435 | run_exp.py                | line 31   : Writing log file to /content/drive/MyDrive/Research-NAS/MCGRAN/exp/MCGRAN/503/log_exp_503.txt\n",
            "INFO  | 2022-12-08 12:21:14,437 | run_exp.py                | line 32   : Exp instance id = 503\n",
            "INFO  | 2022-12-08 12:21:14,438 | run_exp.py                | line 33   : Exp comment = None\n",
            "INFO  | 2022-12-08 12:21:14,438 | run_exp.py                | line 34   : Config =\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "{'dataset': {'data_path': './',\n",
            "             'dev_ratio': 0.2,\n",
            "             'has_node_feat': False,\n",
            "             'is_overwrite_precompute': False,\n",
            "             'is_sample_subgraph': True,\n",
            "             'is_save_split': True,\n",
            "             'loader_name': 'GRANData_Targeted_Search',\n",
            "             'max_num_samples': 1000,\n",
            "             'max_test_accuracy': 100,\n",
            "             'min_test_accuracy': 80,\n",
            "             'name': 'nas',\n",
            "             'node_order': 'none',\n",
            "             'num_fwd_pass': 2,\n",
            "             'num_subgraph_batch': 2,\n",
            "             'train_ratio': 0.8},\n",
            " 'device': 'cuda:0',\n",
            " 'exp_dir': '/content/drive/MyDrive/Research-NAS/MCGRAN/exp/MCGRAN/',\n",
            " 'exp_name': '503',\n",
            " 'free_cache': False,\n",
            " 'gpus': [0],\n",
            " 'model': {'block_size': 1,\n",
            "           'dimension_reduce': True,\n",
            "           'display_detailed_model': False,\n",
            "           'edge_weight': 1.0,\n",
            "           'embedding_dim': 256,\n",
            "           'has_attention': True,\n",
            "           'hidden_dim': 256,\n",
            "           'is_sym': False,\n",
            "           'max_num_nodes': 7,\n",
            "           'name': 'MCGRAN',\n",
            "           'node_categories': 3,\n",
            "           'num_GNN_layers': 7,\n",
            "           'num_GNN_prop': 1,\n",
            "           'num_canonical_order': 1,\n",
            "           'num_mix_component': 64,\n",
            "           'sample_stride': 1},\n",
            " 'run_id': '503',\n",
            " 'runner': 'GranRunner_Evaluation',\n",
            " 'save_dir': '/content/drive/MyDrive/Research-NAS/MCGRAN/exp/MCGRAN/503',\n",
            " 'seed': 78123456,\n",
            " 'test': {'batch_size': 100,\n",
            "          'better_vis': True,\n",
            "          'generated_graph_data_dir': 'generated_data',\n",
            "          'is_single_plot': False,\n",
            "          'is_test_ER': False,\n",
            "          'is_vis': True,\n",
            "          'num_test_gen': 100,\n",
            "          'num_vis': 10,\n",
            "          'num_workers': 0,\n",
            "          'test_model_dir': '/content/drive/MyDrive/ICLR2023/MCGRAN/exp/MCGRAN/58724',\n",
            "          'test_model_name': 'model_snapshot_0000281.pth',\n",
            "          'vis_num_row': 1},\n",
            " 'train': {'batch_size': 20,\n",
            "           'display_iter': 10,\n",
            "           'is_resume': False,\n",
            "           'lr': 0.0001,\n",
            "           'lr_decay': 0.1,\n",
            "           'lr_decay_epoch': [100000000],\n",
            "           'max_epoch': 38,\n",
            "           'momentum': 0.9,\n",
            "           'num_workers': 0,\n",
            "           'optimizer': 'Adam',\n",
            "           'resume_dir': None,\n",
            "           'resume_epoch': 100,\n",
            "           'resume_model': None,\n",
            "           'shuffle': True,\n",
            "           'snapshot_epoch': 38,\n",
            "           'valid_epoch': 50,\n",
            "           'wd': 0.0},\n",
            " 'use_gpu': True,\n",
            " 'use_horovod': False}\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "2022-12-08 12:21:22.404835: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO  | 2022-12-08 12:21:23,277 | gran_runner_evaluation.py | line 113  : Train/val/test = 800/200/200\n",
            "800\n",
            "INFO  | 2022-12-08 12:21:23,283 | gran_runner_evaluation.py | line 154  : No Edges vs. Edges in training set = 4.5721393034825875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "sPnRNrYOCG6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHLqs15zCEdA"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}